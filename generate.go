package gigago

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"net/http"
)

type payload struct {
	Model             string    `json:"model"`
	Messages          []Message `json:"messages"`
	Temperature       float64   `json:"temperature"`
	MaxTokens         int32     `json:"max_tokens"`
	RepetitionPenalty float64   `json:"repetition_penalty"`
	TopP              float64   `json:"top_p"`
}

// CompletionResponse represents the entire response from the GigaChat API for a chat completion request.
type CompletionResponse struct {
	// Choices is a list of completion choices generated by the model. Typically, there is one choice.
	Choices []Choice `json:"choices"`

	// Created is the Unix timestamp (seconds) of when the response was created.
	Created int64 `json:"created"`

	// Model specifies the exact model version used to generate the response.
	Model string `json:"model"`

	// Usage provides statistics on token consumption for the request.
	Usage UsageStats `json:"usage"`

	// Object is the type of the API object, typically "chat.completion".
	Object string `json:"object"`
}

// Choice represents a single completion alternative.
type Choice struct {
	// Message is the actual message object generated by the model.
	Message ResponseMessage `json:"message"`

	// Index is the position of this choice in the list, starting from 0.
	Index int `json:"index"`

	// FinishReason indicates why the model stopped generating tokens.
	// Possible values include: "stop", "length", "function_call", "blacklist", "error".
	FinishReason string `json:"finish_reason"`
}

// ResponseMessage represents a message generated by the assistant.
// It can contain either text content or a request to call a function.
type ResponseMessage struct {
	// Role is the role of the message author, always "assistant" for responses.
	Role Role `json:"role"`

	// Content is the textual content of the message.
	Content string `json:"content"`

	// FunctionCall, if not nil, indicates that the model wants to call a function.
	FunctionCall *FunctionCall `json:"function_call,omitempty"`
}

// FunctionCall represents a model's request to invoke a specific tool or function.
type FunctionCall struct {
	// Name is the name of the function to be called.
	Name string `json:"name"`

	// Arguments is a JSON object containing the arguments for the function call.
	// It is provided as a json.RawMessage to allow for flexible deferred parsing
	// into a user-defined struct.
	Arguments json.RawMessage `json:"arguments"`
}

// UsageStats contains detailed statistics on token usage for a request.
type UsageStats struct {
	// PromptTokens is the number of tokens in the input messages.
	PromptTokens int `json:"prompt_tokens"`

	// CompletionTokens is the number of tokens generated by the model.
	CompletionTokens int `json:"completion_tokens"`

	// PrecachedPromptTokens is the number of cached tokens from the prompt that were
	// reused to process the request, reducing cost and latency.
	PrecachedPromptTokens int `json:"precached_prompt_tokens"`

	// TotalTokens is the total number of tokens billed for the request,
	// calculated after subtracting any precached tokens.
	TotalTokens int `json:"total_tokens"`
}

// Generate sends the provided messages to the model and returns a completion.
// It prepends a system instruction if one is configured on the GenerativeModel.
//
// This method includes a retry mechanism: if the initial request fails with an
// authentication error (HTTP 401), it will attempt to refresh the access token
// and retry the request once. An error is returned if the message slice is empty,
// or if the request fails after the retry attempt.
func (g *GenerativeModel) Generate(ctx context.Context, message []Message) (*CompletionResponse, error) {
	if len(message) == 0 {
		return nil, fmt.Errorf("empty message")
	}
	finalMessages := make([]Message, 0, len(message)+1)
	if g.SystemInstruction != "" {
		finalMessages = append(finalMessages, Message{Role: RoleSystem, Content: g.SystemInstruction})
	}
	finalMessages = append(finalMessages, message...)

	payload := payload{
		Model:             g.fullName,
		Messages:          finalMessages,
		Temperature:       g.Temperature,
		MaxTokens:         g.MaxTokens,
		RepetitionPenalty: g.RepetitionPenalty,
		TopP:              g.TopP,
	}

	jsonData, err := json.Marshal(payload)
	if err != nil {
		return nil, err
	}

	var resp *http.Response

	for i := 0; i < 2; i++ {
		g.c.mu.RLock()
		token := g.c.accessToken.AccessToken
		g.c.mu.RUnlock()
		req, err := http.NewRequestWithContext(ctx, "POST", g.c.baseURLAI, bytes.NewBuffer(jsonData))
		if err != nil {
			return nil, err
		}

		req.Header.Set("Content-Type", "application/json")
		req.Header.Set("Accept", "application/json")
		req.Header.Set("Authorization", "Bearer "+token)

		resp, err = g.c.httpClient.Do(req)
		if err != nil {
			return nil, err
		}

		if resp.StatusCode != http.StatusUnauthorized {
			break
		}

		if i == 1 {
			break
		}

		resp.Body.Close()

		if err := g.c.refreshToken(ctx); err != nil {
			return nil, fmt.Errorf("failed to refresh token after 401: %w", err)
		}
	}

	defer resp.Body.Close()

	if resp.StatusCode == http.StatusOK {
		var result CompletionResponse
		if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
			return nil, err
		}
		return &result, nil
	}

	body, _ := io.ReadAll(resp.Body)
	return nil, fmt.Errorf("unexpected status %d: %s", resp.StatusCode, string(body))
}
